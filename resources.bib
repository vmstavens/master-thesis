% https://www.overleaf.com/learn/latex/Bibliography_management_in_LaTeX#Reference_guide
% http://tug.ctan.org/info/biblatex-cheatsheet/biblatex-cheatsheet.pdf

% tactile sensor technology overview
@Article{recent-progress-in-technologies-for-tactile-sensors,
    AUTHOR         = {Chi, Cheng and Sun, Xuguang and Xue, Ning and Li, Tong and Liu, Chang},
    TITLE          = {Recent Progress in Technologies for Tactile Sensors},
    JOURNAL        = {Sensors},
    VOLUME         = {18},
    YEAR           = {2018},
    NUMBER         = {4},
    ARTICLE-NUMBER = {948},
    URL            = {https://www.mdpi.com/1424-8220/18/4/948},
    ISSN           = {1424-8220},
    ABSTRACT       = {Over the last two decades, considerable scientific and technological efforts have been devoted to developing tactile sensing based on a variety of transducing mechanisms, with prospective applications in many fields such as human–machine interaction, intelligent robot tactile control and feedback, and tactile sensorized minimally invasive surgery. This paper starts with an introduction of human tactile systems, followed by a presentation of the basic demands of tactile sensors. State-of-the-art tactile sensors are reviewed in terms of their diverse sensing mechanisms, design consideration, and material selection. Subsequently, typical performances of the sensors, along with their advantages and disadvantages, are compared and analyzed. Two major potential applications of tactile sensing systems are discussed in detail. Lastly, we propose prospective research directions and market trends of tactile sensing systems.},
    DOI            = {10.3390/s18040948}
}

% pose estimation of transparent objects
@Article{6dof-pose-estimation-of-transparent-object-from-a-single-rgb-d-image,
    AUTHOR         = {Xu, Chi and Chen, Jiale and Yao, Mengyang and Zhou, Jun and Zhang, Lijun and Liu, Yi},
    TITLE          = {6DoF Pose Estimation of Transparent Object from a Single RGB-D Image},
    JOURNAL        = {Sensors},
    VOLUME         = {20},
    YEAR           = {2020},
    NUMBER         = {23},
    ARTICLE-NUMBER = {6790},
    URL            = {https://www.mdpi.com/1424-8220/20/23/6790},
    ISSN           = {1424-8220},
    ABSTRACT       = {6DoF object pose estimation is a foundation for many important applications, such as robotic grasping, automatic driving, and so on. However, it is very challenging to estimate 6DoF pose of transparent object which is commonly seen in our daily life, because the optical characteristics of transparent material lead to significant depth error which results in false estimation. To solve this problem, a two-stage approach is proposed to estimate 6DoF pose of transparent object from a single RGB-D image. In the first stage, the influence of the depth error is eliminated by transparent segmentation, surface normal recovering, and RANSAC plane estimation. In the second stage, an extended point-cloud representation is presented to accurately and efficiently estimate object pose. As far as we know, it is the first deep learning based approach which focuses on 6DoF pose estimation of transparent objects from a single RGB-D image. Experimental results show that the proposed approach can effectively estimate 6DoF pose of transparent object, and it out-performs the state-of-the-art baselines by a large margin.},
    DOI            = {10.3390/s20236790}
}

% comparative study - learning vs. non-learning and 2D data vs. 3D data
@Article{6d-pose-estimation-of-objects:-recent-technologies-and-challenges,
    AUTHOR         = {He, Zaixing and Feng, Wuxi and Zhao, Xinyue and Lv, Yongfeng},
    TITLE          = {6D Pose Estimation of Objects: Recent Technologies and Challenges},
    JOURNAL        = {Applied Sciences},
    VOLUME         = {11},
    YEAR           = {2021},
    NUMBER         = {1},
    ARTICLE-NUMBER = {228},
    URL            = {https://www.mdpi.com/2076-3417/11/1/228},
    ISSN           = {2076-3417},
    ABSTRACT       = {6D pose estimation is a common and important task in industry. Obtaining the 6D pose of objects is the basis for many other functions such as bin picking, autopilot, etc. Therefore, many corresponding studies have been made in order to improve the accuracy and enlarge the range of application of various approaches. After several years of development, the methods of 6D pose estimation have been enriched and improved. Although some predecessors have analyzed the methods and summarized them in detailed, there have been many new breakthroughs in recent years. To understand 6D pose estimation better, this paper will make a new and more detailed review of 6D pose estimation. We divided these methods into two approaches: Learning-based approaches and non-learning-based approaches, including 2D-information-based approach and 3D-information-based approach. Additionally, we introduce the challenges that exist in 6D pose estimation. Finally, we compare the performance of different methods qualitatively and discuss the future development trends of the 6D pose estimation.},
    DOI            = {10.3390/app11010228}
}


@online{shadow-dex-hand,
    AUTHOR         = {Troy Straszheim and Morten Kjaergaard and Brian Gerkey and Dirk Thomas},
    TITLE          = {Shadow Robot},
    URL            = {https://www.shadowrobot.com/dexterous-hand-series/},
    URLDATE        = {Accessed: July 29, 2022}
}

@online{shadow-dex-hand-schematic,
    AUTHOR         = {ROS Components},
    TITLE          = {The Shadow Dexterous Hand},
    URL            = {https://www.roscomponents.com/en/robotic-hands/117-shadow-dexterous-robotic-hand.html},
    URLDATE        = {Accessed: September 19, 2022}
}

@online{docker,
    AUTHOR         = {docker},
    TITLE          = {What is a container},
    URL            = {https://www.docker.com/resources/what-container/},
    URLDATE        = {Accessed: September 19, 2022}
}

@article{ros,
    AUTHOR         = {Quigley, Morgan and Conley, Ken and Gerkey, Brian and Faust, Josh and Foote, Tully and Leibs, Jeremy and Wheeler, Rob and Ng, Andrew},
    YEAR           = {2009},
    MONTH          = {01},
    TITLE          = {ROS: an open-source Robot Operating System},
    VOLUME         = {3},
    JOURNAL        = {ICRA Workshop on Open Source Software}
}

% pen_black 3D model for gazebo
@misc{the-effect-of-color-space-selection-on-detectability-and-discriminability-of-colored-objects,
    DOI            = {10.48550/ARXIV.1702.05421},
    URL            = {https://arxiv.org/abs/1702.05421},
    AUTHOR         = {Rasouli, Amir and Tsotsos, John K.},
    KEYWORDS       = {Computer Vision and Pattern Recognition (cs.CV), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
    TITLE          = {The Effect of Color Space Selection on Detectability and Discriminability of Colored Objects},
    PUBLISHER      = {arXiv},
    YEAR           = {2017}, 
    COPYRIGHT      = {arXiv.org perpetual, non-exclusive license}
}

@article{gazebo, 
    AUTHOR         = {N. {Koenig} and A. {Howard}},
    BOOKTITLE      = {2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)},
    TITLE          = {Design and use paradigms for Gazebo, an open-source multi-robot simulator},
    YEAR           = {2004},
    VOLUME         = {3},
    PAGES          = {2149-2154 vol.3},
    DOI            = {10.1109/IROS.2004.1389727}
}

@article{ros-control,
    AUTHOR         = {Chitta, Sachin and Marder-Eppstein, Eitan and Meeussen, Wim and Pradeep, Vijay and Rodr{\'i}guez Tsouroukdissian, Adolfo  and Bohren, Jonathan and Coleman, David and Magyar, Bence and Raiola, Gennaro and L{\"u}dtke, Mathias and Fern{\'a}ndez Perdomo, Enrique},
    TITLE          = {ros\_control: A generic and simple control framework for ROS},
    JOURNAL        = {The Journal of Open Source Software},
    YEAR           = {2017},
    DOI            = {10.21105/joss.00456},
    URL            = {http://www.theoj.org/joss-papers/joss.00456/10.21105.joss.00456.pdf}
}

@online{shadow-dex-github,
    AUTHOR         = {Shadow Robot},
    TITLE          = {The Shadow Robot Company},
    URL            = {https://github.com/shadow-robot},
    URLDATE        = {Accessed: September 19, 2022}
}

% bin-picking (ros)
@ARTICLE{generic-development-of-bin-pick-and-place-system-based-on-robot-operating-system,
    AUTHOR           = {Wong, Ching-Chang and Tsai, Chi-Yi and Chen, Ren-Jie and Chien, Shao-Yu and Yang, Yi-He and Wong, Shang-Wen and Yeh, Chun-An},
    JOURNAL          = {IEEE Access}, 
    TITLE            = {Generic Development of Bin Pick-and-Place System Based on Robot Operating System}, 
    YEAR             = {2022},
    VOLUME           = {10},
    NUMBER           = {},
    PAGES            = {65257-65270},
    DOI              = {10.1109/ACCESS.2022.3182114}
}

% waste sorting
@INPROCEEDINGS{robotic-pick-and-toss-facilitates-urban-waste-sorting,
    AUTHOR           = {Raptopoulos, Fredy and Koskinopoulou, Maria and Maniadakis, Michail},
    BOOKTITLE        = {2020 IEEE 16th International Conference on Automation Science and Engineering (CASE)}, 
    TITLE            = {Robotic Pick-and-Toss Facilitates Urban Waste Sorting}, 
    YEAR             = {2020},
    VOLUME           = {},
    NUMBER           = {},
    PAGES            = {1149-1154},
    DOI              = {10.1109/CASE48305.2020.9216746}
}

% Small food robot handling trays
@misc{automation-of-mobile-pick-and-place-robotic-system-for-small-food-industry,
    DOI                = {10.48550/ARXIV.1203.4475},
    URL                = {https://arxiv.org/abs/1203.4475},
    AUTHOR             = {Talpur, Mir Sajjad Hussain and Shaikh, Murtaza Hussain},
    KEYWORDS           = {Emerging Technologies (cs.ET), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences, D.3.2; H.3.4},
    TITLE              = {Automation of Mobile Pick and Place Robotic System for Small Food Industry},
    PUBLISHER          = {arXiv},
    YEAR               = {2012},
    COPYRIGHT          = {arXiv.org perpetual, non-exclusive license}
}

% handling soft food
@INPROCEEDINGS{development-of-a-food-handling-soft-robot-hand-considering-a-high-speed-pick-and-place-task,
    AUTHOR           = {Yamanaka, Yuta and Katagiri, Sho and Nabae, Hiroyuki and Suzumori, Koichi and Endo, Gen},
    BOOKTITLE        = {2020 IEEE/SICE International Symposium on System Integration (SII)}, 
    TITLE            = {Development of a Food Handling Soft Robot Hand Considering a High-speed Pick-and-place Task}, 
    YEAR             = {2020},
    VOLUME           = {},
    NUMBER           = {},
    PAGES            = {87-92},
    DOI              = {10.1109/SII46433.2020.9026282}
}

% industrial bin-picking
@INPROCEEDINGS{real-time-industrial-bin-picking-with-a-hybrid-deep-learning-engineering-approach,
    AUTHOR           = {Lee, Sukhan and Lee, Yeonho},
    BOOKTITLE        = {2020 IEEE International Conference on Big Data and Smart Computing (BigComp)}, 
    TITLE            = {Real-Time Industrial Bin-Picking with a Hybrid Deep Learning-Engineering Approach}, 
    YEAR             = {2020},
    VOLUME           = {},
    NUMBER           = {},
    PAGES            = {584-588},
    DOI              = {10.1109/BigComp48618.2020.00015}
}

% industrial bin-picking benchmark
@ARTICLE{a-bin-picking-benchmark-for-systematic-evaluation-of-robotic-pick-and-place-systems,
    AUTHOR           = {Mnyusiwalla, Hussein and Triantafyllou, Pavlos and Sotiropoulos, Panagiotis and Roa, Máximo A. and Friedl, Werner and Sundaram, Ashok M. and Russell, Duncan and Deacon, Graham},
    JOURNAL          = {IEEE Robotics and Automation Letters}, 
    TITLE            = {A Bin-Picking Benchmark for Systematic Evaluation of Robotic Pick-and-Place Systems}, 
    YEAR             = {2020},
    VOLUME           = {5},
    NUMBER           = {2},
    PAGES            = {1389-1396},
    DOI              = {10.1109/LRA.2020.2965076}
}

% stereo vision pose estimation
@inproceedings{3d-object-pose-estimation-using-stereo-vision-for-object-manipulation-system,
    AUTHOR           = {., Taryudi and Wang, Ming-Shyan},
    YEAR             = {2017},
    MONTH            = {05},
    PAGES            = {1532-1535},
    TITLE            = {3D object pose estimation using stereo vision for object manipulation system},
    DOI              = {10.1109/ICASI.2017.7988217}
}

% combine stereo and dl
@article{stereo-vision-based-single-shot-6d-object-pose-estimation-for-bin-picking-by-a-robot-manipulator,
    author           = {Yoshihiro Nakano},
    title            = {Stereo Vision Based Single-Shot 6D Object Pose Estimation for Bin-Picking by a Robot Manipulator},
    journal          = {CoRR},
    volume           = {abs/2005.13759},
    year             = {2020},
    url              = {https://arxiv.org/abs/2005.13759},
    eprinttype       = {arXiv},
    eprint           = {2005.13759},
    timestamp        = {Wed, 03 Jun 2020 11:36:54 +0200},
    biburl           = {https://dblp.org/rec/journals/corr/abs-2005-13759.bib},
    bibsource        = {dblp computer science bibliography, https://dblp.org}
}

% stereo vision pose estimation + geometric pattern matching (GPM)
﻿@Article{stereo-vision-based-automation-for-a-bin-picking-solution,
    AUTHOR           = {Oh, Jong-Kyu and Lee, Sukhan and Lee, Chan-Ho},
    TITLE            = {Stereo vision based automation for a bin-picking solution},
    JOURNAL          = {International Journal of Control, Automation and Systems},
    YEAR             = {2012},
    MONTH            = {Apr},
    DAY              = {01},
    VOLUME           = {10},
    NUMBER           = {2},
    PAGES            = {362-373},
    ABSTRACT         = {As flexibility becomes an important factor in factory automation, the bin-picking system, where a robot performs pick-and-place tasks for randomly piled parts in a bin through measuring the 3D pose of an object by a 3D vision sensor, has been actively studied. However, conventional bin-picking systems that are employed for particular tasks are limited by such things as the FOV (Field of View), the shape of landmark features, and computation time. This paper proposes a general-purpose stereo vision based bin-picking system. To detect the workpiece to be picked, a geometric pattern matching (GPM) method with respect to the 2D image with a wide FOV is applied. The accurate 3D pose of a selected workpiece among the pick-up candidates is acquired by measuring the 3D positions of three features in the workpiece using the stereo camera. In order to improve the 3D position estimation performance, the GPM method is also used instead of the stereo matching method. The multiple pattern registration and ellipse fitting techniques are additionally applied to increase the reliability. The grasp position of a workpiece without collision is determined using the pose of the object and the bin information. By using these methods a practical bin-picking strategy is established to operate robustly with minimum help from the human workers in the factory. Through experiments on commercial industrial workpieces and industrial robot, we validated that the proposed vision system accurately measures the 3D pose of part and the robot successfully manipulates the workpiece among randomly stacked parts.},
    ISSN             = {2005-4092},
    DOI              = {10.1007/s12555-012-0216-9},
    URL              = {https://doi.org/10.1007/s12555-012-0216-9}
}

% dl (cnn) pose estimation
@article{uncalibrated-stereo-vision-with-deep-learning-for-6-dof-pose-estimation-for-a-robot-arm-system,
    TITLE            = {Uncalibrated stereo vision with deep learning for 6-DOF pose estimation for a robot arm system},
    JOURNAL          = {Robotics and Autonomous Systems},
    VOLUME           = {145},
    PAGES            = {103847},
    YEAR             = {2021},
    ISSN             = {0921-8890},
    DOI              = {https://doi.org/10.1016/j.robot.2021.103847},
    URL              = {https://www.sciencedirect.com/science/article/pii/S0921889021001329},
    AUTHOR           = {Mahmoud Abdelaal and Ramy M.A. Farag and Mohamed S. Saad and Ahmed Bahgat and Hassan M. Emara and Ayman El-Dessouki},
    KEYWORDS         = {Deep learning, Pose estimation, Robot vision, Stereo vision, Optimization techniques, Levenberg–Marquardt algorithm},
    ABSTRACT         = {This paper proposes a novel method for six degrees of freedom pose estimation of objects for the application of robot arm pick and place. It is based on the use of a stereo vision system, which does not require calibration. Using both cameras, four corner points of the object are detected. A deep-neural-network (DNN) is trained for the prediction of the 6 DOF pose of the object from the four detected corner points’ coordinates in each image of both cameras. The stereo vision used is a low-end vision system placed in a custom-made setup. Before the training phase of the DNN, the robot is set to auto collect data in a predefined workspace. This workspace is defined dependently on the spatial feasibility of the robot arm and the shared field of view of the stereo vision system. The collected data represent images of a 2D marker attached to the robot arm gripper. The 2D marker is used for data collection to ease the detection of the four corner points. The proposed method succeeds in estimating the six degrees of freedom pose of the object, without the need for the determination of neither the intrinsic nor the extrinsic parameters of the stereo vision system. The optimum design of the proposed DNN is obtained after comparing different activation functions and optimizers associated with the DNN. The proposed uncalibrated DNN-based method performance is compared to that of the traditional calibration-based method. In the calibration-based method, the rotational matrix relating the robot coordinates to the stereo vision coordinates is computed using two approaches. The first approach uses Singular Value Decomposition (SVD) while the second approach uses a novel proposed modification of particle swarm optimization (PSO) called Hyper particle Scouts optimization (HPSO). HPSO outperforms other metaheuristic optimization algorithms such as PSO and genetic algorithm (GA). Exhaustive tests are performed, and the proposed DNN-based method is shown to outperform all tested alternatives.}
}

% reflective object pose estimation (dl)
@Article{data-driven-object-pose-estimation-in-a-practical-bin-picking-application,
    AUTHOR           = {Kozák, Viktor and Sushkov, Roman and Kulich, Miroslav and Přeučil, Libor},
    TITLE            = {Data-Driven Object Pose Estimation in a Practical Bin-Picking Application},
    JOURNAL          = {Sensors},
    VOLUME           = {21},
    YEAR             = {2021},
    NUMBER           = {18},
    ARTICLE-NUMBER   = {6093},
    URL              = {https://www.mdpi.com/1424-8220/21/18/6093},
    PubMedID         = {34577303},
    ISSN             = {1424-8220},
    ABSTRACT         = {This paper addresses the problem of pose estimation from 2D images for textureless industrial metallic parts for a semistructured bin-picking task. The appearance of metallic reflective parts is highly dependent on the camera viewing direction, as well as the distribution of light on the object, making conventional vision-based methods unsuitable for the task. We propose a solution using direct light at a fixed position to the camera, mounted directly on the robot’s gripper, that allows us to take advantage of the reflective properties of the manipulated object. We propose a data-driven approach based on convolutional neural networks (CNN), without the need for a hard-coded geometry of the manipulated object. The solution was modified for an industrial application and extensively tested in a real factory. Our solution uses a cheap 2D camera and allows for a semi-automatic data-gathering process on-site.},
    DOI              = {10.3390/s21186093}
}

% UN "umanity has developed tools for unprecedented growth in wealth and technology on a global scale"
@inbook{technology-and-inequalities,
    AUTHOR           = {United Nations Publications},
    TITLE            = {Inequality in Asia and the Pacific in the Era of the 2030 Agenda for Sustainable Development},
    YEAR             = {07 May 2018},
    URL              = {https://www.unescap.org/publications/inequality-asia-and-pacific-era-2030-agenda-sustainable-development},
    ABSTRACT         = {This paper addresses the problem of pose estimation from 2D images for textureless industrial metallic parts for a semistructured bin-picking task. The appearance of metallic reflective parts is highly dependent on the camera viewing direction, as well as the distribution of light on the object, making conventional vision-based methods unsuitable for the task. We propose a solution using direct light at a fixed position to the camera, mounted directly on the robot’s gripper, that allows us to take advantage of the reflective properties of the manipulated object. We propose a data-driven approach based on convolutional neural networks (CNN), without the need for a hard-coded geometry of the manipulated object. The solution was modified for an industrial application and extensively tested in a real factory. Our solution uses a cheap 2D camera and allows for a semi-automatic data-gathering process on-site.},
}

% human error
@article{analysis-and-control-of-human-error,
    AUTHOR           = {Wenwen, Shi and Fuchuan, Jiang and Qiang, Zheng and Jingjing, Cui},
    YEAR             = {2011},
    MONTH            = {12},
    PAGES            = {2126-2132},
    TITLE            = {Analysis and Control of Human Error},
    VOLUME           = {26},
    JOURNAL          = {Procedia Engineering},
    DOI              = {10.1016/j.proeng.2011.11.2415}
}

% cobots
@article{cobots-and-the-benefits-of-their-implementation-in-intelligent-manufacturing,
    AUTHOR           = {Galin, Rinat and Meshcheryakov, Roman and Kamesheva, Saniya and Samoshina, Anna},
    YEAR             = {2020},
    MONTH            = {05},
    PAGES            = {032075},
    TITLE            = {Cobots and the benefits of their implementation in intelligent manufacturing},
    VOLUME           = {862},
    JOURNAL          = {IOP Conference Series: Materials Science and Engineering},
    DOI              = {10.1088/1757-899X/862/3/032075}
}